// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py UTC_ARGS: --replace-value-regex "!annotation ![0-9]+" "!tbaa ![0-9]+" "!tbaa\.struct ![0-9]+" "!nosanitize ![0-9]+" "!srcloc ![0-9]+" --prefix-filecheck-ir-name TMP_

// RUN: %clang_cc1 -O0 -fbounds-safety -emit-llvm -triple x86_64 %s -o - | FileCheck %s

#include <ptrcheck.h>

// CHECK-LABEL: @for_cond_inc(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[P_ADDR:%.*]] = alloca ptr, align 8
// CHECK-NEXT:    [[LEN_ADDR:%.*]] = alloca i64, align 8
// CHECK-NEXT:    [[VAL:%.*]] = alloca i8, align 1
// CHECK-NEXT:    [[AGG_TEMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP3:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[TMP:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP6:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP13:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP17:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP20:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP28:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP31:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP42:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP57:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[TMP_TMP58:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP64:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP71:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP77:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP80:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP90:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    [[AGG_TEMP93:%.*]] = alloca %"__bounds_safety::wide_ptr.bidi_indexable", align 8
// CHECK-NEXT:    store ptr [[P:%.*]], ptr [[P_ADDR]], align 8
// CHECK-NEXT:    store i64 [[LEN:%.*]], ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[TMP0:%.*]] = load ptr, ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[CMP:%.*]] = icmp sge i64 [[TMP1]], 0
// CHECK-NEXT:    call void @llvm.assume(i1 [[CMP]])
// CHECK-NEXT:    [[ADD_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP0]], i64 [[TMP1]]
// CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP2]], align 8
// CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR]], ptr [[TMP3]], align 8
// CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP0]], ptr [[TMP4]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR]], align 8
// CHECK-NEXT:    [[TMP5:%.*]] = icmp ult ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_UB]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP5]], label [[CONT:%.*]], label [[TRAP:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4:[0-9]+]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable
// CHECK:       cont:
// CHECK-NEXT:    [[TMP6:%.*]] = icmp uge ptr [[WIDE_PTR_PTR]], [[WIDE_PTR_LB]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP6]], label [[CONT2:%.*]], label [[TRAP1:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap1:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable
// CHECK:       cont2:
// CHECK-NEXT:    [[TMP7:%.*]] = load i8, ptr [[WIDE_PTR_PTR]], align 1
// CHECK-NEXT:    store i8 [[TMP7]], ptr [[VAL]], align 1
// CHECK-NEXT:    [[TMP8:%.*]] = load ptr, ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[TMP9:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[CMP4:%.*]] = icmp sge i64 [[TMP9]], 0
// CHECK-NEXT:    call void @llvm.assume(i1 [[CMP4]])
// CHECK-NEXT:    [[ADD_PTR5:%.*]] = getelementptr inbounds i8, ptr [[TMP8]], i64 [[TMP9]]
// CHECK-NEXT:    [[TMP10:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP10]], align 8
// CHECK-NEXT:    [[TMP11:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR5]], ptr [[TMP11]], align 8
// CHECK-NEXT:    [[TMP12:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP8]], ptr [[TMP12]], align 8
// CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 0
// CHECK-NEXT:    [[TMP14:%.*]] = load ptr, ptr [[TMP13]], align 8
// CHECK-NEXT:    [[BOUND_PTR_ARITH:%.*]] = getelementptr i8, ptr [[TMP14]], i64 1
// CHECK-NEXT:    [[TMP15:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[BOUND_PTR_ARITH]], ptr [[TMP15]], align 8
// CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 1
// CHECK-NEXT:    [[TMP17:%.*]] = load ptr, ptr [[TMP16]], align 8
// CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP17]], ptr [[TMP18]], align 8
// CHECK-NEXT:    [[TMP19:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP]], i32 0, i32 2
// CHECK-NEXT:    [[TMP20:%.*]] = load ptr, ptr [[TMP19]], align 8
// CHECK-NEXT:    [[TMP21:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP3]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP20]], ptr [[TMP21]], align 8
// CHECK-NEXT:    [[TMP22:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[SUB:%.*]] = sub i64 [[TMP22]], 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP6]], ptr align 8 [[AGG_TEMP3]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR7:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP6]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR8:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR7]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR9:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP6]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB10:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR9]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR11:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP6]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB12:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR11]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP13]], ptr align 8 [[AGG_TEMP3]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR14:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP13]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB15:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR14]], align 8
// CHECK-NEXT:    [[CMP16:%.*]] = icmp ule ptr [[WIDE_PTR_PTR8]], [[WIDE_PTR_UB15]]
// CHECK-NEXT:    br i1 [[CMP16]], label [[LAND_LHS_TRUE:%.*]], label [[LAND_END:%.*]]
// CHECK:       land.lhs.true:
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP17]], ptr align 8 [[AGG_TEMP3]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR18:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP17]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB19:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR18]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP20]], ptr align 8 [[AGG_TEMP3]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR21:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP20]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR22:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR21]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR23:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP20]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB24:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR23]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR25:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP20]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB26:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR25]], align 8
// CHECK-NEXT:    [[CMP27:%.*]] = icmp ule ptr [[WIDE_PTR_LB19]], [[WIDE_PTR_PTR22]]
// CHECK-NEXT:    br i1 [[CMP27]], label [[LAND_RHS:%.*]], label [[LAND_END]]
// CHECK:       land.rhs:
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP28]], ptr align 8 [[AGG_TEMP3]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR29:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP28]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB30:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR29]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP31]], ptr align 8 [[AGG_TEMP3]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR32:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP31]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR33:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR32]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR34:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP31]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB35:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR34]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR36:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP31]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB37:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR36]], align 8
// CHECK-NEXT:    [[SUB_PTR_LHS_CAST:%.*]] = ptrtoint ptr [[WIDE_PTR_UB30]] to i64
// CHECK-NEXT:    [[SUB_PTR_RHS_CAST:%.*]] = ptrtoint ptr [[WIDE_PTR_PTR33]] to i64
// CHECK-NEXT:    [[SUB_PTR_SUB:%.*]] = sub i64 [[SUB_PTR_LHS_CAST]], [[SUB_PTR_RHS_CAST]]
// CHECK-NEXT:    [[CMP38:%.*]] = icmp ule i64 [[SUB]], [[SUB_PTR_SUB]]
// CHECK-NEXT:    br label [[LAND_END]]
// CHECK:       land.end:
// CHECK-NEXT:    [[TMP23:%.*]] = phi i1 [ false, [[LAND_LHS_TRUE]] ], [ false, [[CONT2]] ], [ [[CMP38]], [[LAND_RHS]] ], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP23]], label [[CONT40:%.*]], label [[TRAP39:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap39:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable
// CHECK:       cont40:
// CHECK-NEXT:    [[TMP24:%.*]] = load ptr, ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[INCDEC_PTR:%.*]] = getelementptr inbounds i8, ptr [[TMP24]], i32 1
// CHECK-NEXT:    store ptr [[INCDEC_PTR]], ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[TMP25:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[DEC:%.*]] = add i64 [[TMP25]], -1
// CHECK-NEXT:    store i64 [[DEC]], ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    br label [[FOR_COND:%.*]]
// CHECK:       for.cond:
// CHECK-NEXT:    [[TMP26:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[CMP41:%.*]] = icmp ugt i64 [[TMP26]], 0
// CHECK-NEXT:    br i1 [[CMP41]], label [[FOR_BODY:%.*]], label [[FOR_END:%.*]]
// CHECK:       for.body:
// CHECK-NEXT:    [[TMP27:%.*]] = load ptr, ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[TMP28:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[CMP43:%.*]] = icmp sge i64 [[TMP28]], 0
// CHECK-NEXT:    call void @llvm.assume(i1 [[CMP43]])
// CHECK-NEXT:    [[ADD_PTR44:%.*]] = getelementptr inbounds i8, ptr [[TMP27]], i64 [[TMP28]]
// CHECK-NEXT:    [[TMP29:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP42]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP27]], ptr [[TMP29]], align 8
// CHECK-NEXT:    [[TMP30:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP42]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR44]], ptr [[TMP30]], align 8
// CHECK-NEXT:    [[TMP31:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP42]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP27]], ptr [[TMP31]], align 8
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR45:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP42]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR46:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR45]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR47:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP42]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB48:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR47]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR49:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP42]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB50:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR49]], align 8
// CHECK-NEXT:    [[TMP32:%.*]] = icmp ult ptr [[WIDE_PTR_PTR46]], [[WIDE_PTR_UB48]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP32]], label [[CONT52:%.*]], label [[TRAP51:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap51:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable
// CHECK:       cont52:
// CHECK-NEXT:    [[TMP33:%.*]] = icmp uge ptr [[WIDE_PTR_PTR46]], [[WIDE_PTR_LB50]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP33]], label [[CONT54:%.*]], label [[TRAP53:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap53:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable
// CHECK:       cont54:
// CHECK-NEXT:    [[TMP34:%.*]] = load i8, ptr [[WIDE_PTR_PTR46]], align 1
// CHECK-NEXT:    [[CONV:%.*]] = sext i8 [[TMP34]] to i32
// CHECK-NEXT:    [[TMP35:%.*]] = load i8, ptr [[VAL]], align 1
// CHECK-NEXT:    [[CONV55:%.*]] = sext i8 [[TMP35]] to i32
// CHECK-NEXT:    [[ADD:%.*]] = add nsw i32 [[CONV55]], [[CONV]]
// CHECK-NEXT:    [[CONV56:%.*]] = trunc i32 [[ADD]] to i8
// CHECK-NEXT:    store i8 [[CONV56]], ptr [[VAL]], align 1
// CHECK-NEXT:    br label [[FOR_INC:%.*]]
// CHECK:       for.inc:
// CHECK-NEXT:    [[TMP36:%.*]] = load ptr, ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[TMP37:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[CMP59:%.*]] = icmp sge i64 [[TMP37]], 0
// CHECK-NEXT:    call void @llvm.assume(i1 [[CMP59]])
// CHECK-NEXT:    [[ADD_PTR61:%.*]] = getelementptr inbounds i8, ptr [[TMP36]], i64 [[TMP37]]
// CHECK-NEXT:    [[TMP38:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP_TMP58]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[TMP36]], ptr [[TMP38]], align 8
// CHECK-NEXT:    [[TMP39:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP_TMP58]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[ADD_PTR61]], ptr [[TMP39]], align 8
// CHECK-NEXT:    [[TMP40:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP_TMP58]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP36]], ptr [[TMP40]], align 8
// CHECK-NEXT:    [[TMP41:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP_TMP58]], i32 0, i32 0
// CHECK-NEXT:    [[TMP42:%.*]] = load ptr, ptr [[TMP41]], align 8
// CHECK-NEXT:    [[BOUND_PTR_ARITH62:%.*]] = getelementptr i8, ptr [[TMP42]], i64 1
// CHECK-NEXT:    [[TMP43:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP57]], i32 0, i32 0
// CHECK-NEXT:    store ptr [[BOUND_PTR_ARITH62]], ptr [[TMP43]], align 8
// CHECK-NEXT:    [[TMP44:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP_TMP58]], i32 0, i32 1
// CHECK-NEXT:    [[TMP45:%.*]] = load ptr, ptr [[TMP44]], align 8
// CHECK-NEXT:    [[TMP46:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP57]], i32 0, i32 1
// CHECK-NEXT:    store ptr [[TMP45]], ptr [[TMP46]], align 8
// CHECK-NEXT:    [[TMP47:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[TMP_TMP58]], i32 0, i32 2
// CHECK-NEXT:    [[TMP48:%.*]] = load ptr, ptr [[TMP47]], align 8
// CHECK-NEXT:    [[TMP49:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP57]], i32 0, i32 2
// CHECK-NEXT:    store ptr [[TMP48]], ptr [[TMP49]], align 8
// CHECK-NEXT:    [[TMP50:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[SUB63:%.*]] = sub i64 [[TMP50]], 1
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP64]], ptr align 8 [[AGG_TEMP57]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR65:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP64]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR66:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR65]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR67:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP64]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB68:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR67]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR69:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP64]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB70:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR69]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP71]], ptr align 8 [[AGG_TEMP57]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR72:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP71]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB73:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR72]], align 8
// CHECK-NEXT:    [[CMP74:%.*]] = icmp ule ptr [[WIDE_PTR_PTR66]], [[WIDE_PTR_UB73]]
// CHECK-NEXT:    br i1 [[CMP74]], label [[LAND_LHS_TRUE76:%.*]], label [[LAND_END105:%.*]]
// CHECK:       land.lhs.true76:
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP77]], ptr align 8 [[AGG_TEMP57]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR78:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP77]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB79:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR78]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP80]], ptr align 8 [[AGG_TEMP57]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR81:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP80]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR82:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR81]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR83:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP80]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB84:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR83]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR85:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP80]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB86:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR85]], align 8
// CHECK-NEXT:    [[CMP87:%.*]] = icmp ule ptr [[WIDE_PTR_LB79]], [[WIDE_PTR_PTR82]]
// CHECK-NEXT:    br i1 [[CMP87]], label [[LAND_RHS89:%.*]], label [[LAND_END105]]
// CHECK:       land.rhs89:
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP90]], ptr align 8 [[AGG_TEMP57]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR91:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP90]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB92:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR91]], align 8
// CHECK-NEXT:    call void @llvm.memcpy.p0.p0.i64(ptr align 8 [[AGG_TEMP93]], ptr align 8 [[AGG_TEMP57]], i64 24, i1 false)
// CHECK-NEXT:    [[WIDE_PTR_PTR_ADDR94:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP93]], i32 0, i32 0
// CHECK-NEXT:    [[WIDE_PTR_PTR95:%.*]] = load ptr, ptr [[WIDE_PTR_PTR_ADDR94]], align 8
// CHECK-NEXT:    [[WIDE_PTR_UB_ADDR96:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP93]], i32 0, i32 1
// CHECK-NEXT:    [[WIDE_PTR_UB97:%.*]] = load ptr, ptr [[WIDE_PTR_UB_ADDR96]], align 8
// CHECK-NEXT:    [[WIDE_PTR_LB_ADDR98:%.*]] = getelementptr inbounds %"__bounds_safety::wide_ptr.bidi_indexable", ptr [[AGG_TEMP93]], i32 0, i32 2
// CHECK-NEXT:    [[WIDE_PTR_LB99:%.*]] = load ptr, ptr [[WIDE_PTR_LB_ADDR98]], align 8
// CHECK-NEXT:    [[SUB_PTR_LHS_CAST100:%.*]] = ptrtoint ptr [[WIDE_PTR_UB92]] to i64
// CHECK-NEXT:    [[SUB_PTR_RHS_CAST101:%.*]] = ptrtoint ptr [[WIDE_PTR_PTR95]] to i64
// CHECK-NEXT:    [[SUB_PTR_SUB102:%.*]] = sub i64 [[SUB_PTR_LHS_CAST100]], [[SUB_PTR_RHS_CAST101]]
// CHECK-NEXT:    [[CMP103:%.*]] = icmp ule i64 [[SUB63]], [[SUB_PTR_SUB102]]
// CHECK-NEXT:    br label [[LAND_END105]]
// CHECK:       land.end105:
// CHECK-NEXT:    [[TMP51:%.*]] = phi i1 [ false, [[LAND_LHS_TRUE76]] ], [ false, [[FOR_INC]] ], [ [[CMP103]], [[LAND_RHS89]] ], {{!annotation ![0-9]+}}
// CHECK-NEXT:    br i1 [[TMP51]], label [[CONT107:%.*]], label [[TRAP106:%.*]], {{!annotation ![0-9]+}}
// CHECK:       trap106:
// CHECK-NEXT:    call void @llvm.ubsantrap(i8 25) #[[ATTR4]], {{!annotation ![0-9]+}}
// CHECK-NEXT:    unreachable
// CHECK:       cont107:
// CHECK-NEXT:    [[TMP52:%.*]] = load ptr, ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[INCDEC_PTR108:%.*]] = getelementptr inbounds i8, ptr [[TMP52]], i32 1
// CHECK-NEXT:    store ptr [[INCDEC_PTR108]], ptr [[P_ADDR]], align 8
// CHECK-NEXT:    [[TMP53:%.*]] = load i64, ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    [[DEC109:%.*]] = add i64 [[TMP53]], -1
// CHECK-NEXT:    store i64 [[DEC109]], ptr [[LEN_ADDR]], align 8
// CHECK-NEXT:    br label [[FOR_COND]], !llvm.loop [[LOOP5:![0-9]+]]
// CHECK:       for.end:
// CHECK-NEXT:    [[TMP54:%.*]] = load i8, ptr [[VAL]], align 1
// CHECK-NEXT:    ret i8 [[TMP54]]
//
char for_cond_inc(char *__sized_by(len) p, unsigned long long len) {
  char val = *p;
  for (p++, len--; len > 0; p++, len--) {
    val += *p;
  }
  return val;
}
